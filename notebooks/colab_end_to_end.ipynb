{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Algo DRL SAC/IQL — Colab End-to-End (Cloud GPU Optimized)\n",
        "\n",
        "This notebook runs the full DRL pipeline on Google Colab with T4/A100 GPU:\n",
        "- **Step 1**: Data download (BTCUSDT hourly OHLCV)\n",
        "- **Step 2**: IQL offline pretraining (200K steps, ~2-3 hours)\n",
        "- **Step 3**: IQL-only evaluation (measure offline RL baseline)\n",
        "- **Step 4**: SAC online fine-tuning (loads IQL weights, ~1-2 hours)\n",
        "- **Step 5**: Final evaluation & comparison\n",
        "\n",
        "**Key Features**:\n",
        "- Separated IQL/SAC for independent execution\n",
        "- Cloud-optimized parameters (200K IQL, proper SAC steps)\n",
        "- Runtime overrides keep repo YAMLs unchanged\n",
        "- IQL-only baseline to measure SAC improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU / CUDA summary (works with or without GPU)\n",
        "import shutil, importlib\n",
        "print('nvidia-smi path:', shutil.which('nvidia-smi'))\n",
        "torch = importlib.import_module('torch')\n",
        "print('torch.cuda.is_available:', torch.cuda.is_available())\n",
        "print('torch.version.cuda:', getattr(torch.version, 'cuda', None))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "# Remove legacy gym to avoid conflicts\n",
        "pip -q uninstall -y gym || true\n",
        "# Try cu121 first; fallback to default wheels\n",
        "pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 || pip -q install torch torchvision torchaudio\n",
        "# Core libraries\n",
        "pip -q install d3rlpy==2.8.1 gymnasium pandas numpy plotly vectorbt requests pyyaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clone your repository (always pulls latest)\n",
        "Set REPO_URL to your GitHub repo. If private, paste a token when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, pathlib\n",
        "from getpass import getpass\n",
        "REPO_URL = os.environ.get('REPO_URL', 'https://github.com/enluha/algo-drl-sac-iql')\n",
        "BRANCH   = os.environ.get('REPO_BRANCH', 'master')\n",
        "TARGET   = pathlib.Path('/content/algo-drl-sac-iql')\n",
        "if 'your-account' in REPO_URL:\n",
        "    raise SystemExit('Please set REPO_URL to your GitHub repository URL (public) or paste a token for private repos.')\n",
        "if TARGET.exists():\n",
        "    %cd /content/algo-drl-sac-iql\n",
        "    !git fetch origin $BRANCH && git checkout $BRANCH && git pull\n",
        "else:\n",
        "    token = ''\n",
        "    try:\n",
        "        token = getpass('GitHub token (press Enter if public): ')\n",
        "    except Exception:\n",
        "        token = ''\n",
        "    if token:\n",
        "        auth_url = REPO_URL.replace('https://', f'https://{token}@')\n",
        "        !git clone -b $BRANCH $auth_url $TARGET\n",
        "    else:\n",
        "        !git clone -b $BRANCH $REPO_URL $TARGET\n",
        "    %cd /content/algo-drl-sac-iql\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cloud Training Configuration (Overrides repo YAMLs at runtime)\n",
        "\n",
        "**Production Mode**: Remove QA_STEPS to use cloud-optimized values below.  \n",
        "**Quick Test**: Set `QA_STEPS='10000'` for 15-min smoke test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ============================================================================\n",
        "# CLOUD-OPTIMIZED TRAINING PARAMETERS (overrides repo YAMLs at runtime)\n",
        "# ============================================================================\n",
        "\n",
        "# Environment setup\n",
        "os.environ['QA_DEVICE'] = 'cuda'\n",
        "os.environ['CONFIG'] = 'config/config.yaml'\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# TRAINING STEPS - Comment out for PRODUCTION, or set lower for quick test\n",
        "# ------------------------------------------------------------------------------\n",
        "# os.environ['QA_STEPS'] = '10000'  # Quick test (~15 min total)\n",
        "# os.environ['QA_STEPS'] = '50000'  # Medium test (~1 hour total)\n",
        "# If QA_STEPS is NOT set, uses cloud-optimized values below:\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# IQL OFFLINE PRETRAINING (if QA_STEPS not set)\n",
        "# ------------------------------------------------------------------------------\n",
        "os.environ['CLOUD_IQL_STEPS'] = '200000'  # 200K steps (~2-3 hours on T4/A100)\n",
        "# Recommended: 200K-300K for production, 100K minimum for decent policy\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SAC ONLINE FINE-TUNING (if QA_STEPS not set)\n",
        "# ------------------------------------------------------------------------------\n",
        "os.environ['CLOUD_SAC_STEPS'] = '100000'  # 100K steps (~1-2 hours)\n",
        "# SAC needs fewer steps since it starts from trained IQL policy\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# NETWORK ARCHITECTURE (cloud GPU can handle larger networks)\n",
        "# ------------------------------------------------------------------------------\n",
        "os.environ['CLOUD_HIDDEN_UNITS'] = '512,512,256'  # Larger capacity for cloud\n",
        "# Default repo: [256, 256]. Cloud upgrade: [512, 512, 256] for better learning\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# BUFFER & BATCH SIZE (utilize GPU memory efficiently)\n",
        "# ------------------------------------------------------------------------------\n",
        "os.environ['CLOUD_BATCH_SIZE'] = '512'  # Larger batches for faster training\n",
        "# Default: 256. Cloud: 512 for better gradient estimates & GPU utilization\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SUMMARY\n",
        "# ------------------------------------------------------------------------------\n",
        "print('=' * 80)\n",
        "print('CLOUD TRAINING CONFIGURATION')\n",
        "print('=' * 80)\n",
        "print(f\"Device:              {os.environ['QA_DEVICE']}\")\n",
        "print(f\"Config:              {os.environ['CONFIG']}\")\n",
        "print(f\"QA_STEPS Override:   {os.environ.get('QA_STEPS', 'NOT SET (using cloud values below)')}\")\n",
        "print(f\"IQL Training Steps:  {os.environ['CLOUD_IQL_STEPS']}\")\n",
        "print(f\"SAC Training Steps:  {os.environ['CLOUD_SAC_STEPS']}\")\n",
        "print(f\"Network Architecture: {os.environ['CLOUD_HIDDEN_UNITS']}\")\n",
        "print(f\"Batch Size:          {os.environ['CLOUD_BATCH_SIZE']}\")\n",
        "print('=' * 80)\n",
        "print('\\nEstimated Training Time (T4 GPU):')\n",
        "print('  - IQL: 2-3 hours (200K steps)')\n",
        "print('  - SAC: 1-2 hours (100K steps)')\n",
        "print('  - Total: ~3-5 hours for full pipeline')\n",
        "print('=' * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Download OHLCV (with volume fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python scripts/download_ohlcv_binance.py --symbol BTCUSDT --interval 3600 --start '2024-06-10' --end '2025-10-16' --output-dir data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) IQL Offline Pretraining (200K steps, ~2-3 hours)\n",
        "\n",
        "Trains the IQL policy from offline expert demonstrations with auxiliary task (price direction prediction).\n",
        "\n",
        "**What happens**:\n",
        "- Loads dataset with momentum expert labels\n",
        "- Trains multi-task encoder (policy + 24h price prediction)\n",
        "- Generates IQL-only evaluation files for baseline comparison\n",
        "- Saves model to `evaluation/artifacts/iql_policy.d3`\n",
        "\n",
        "**Output Files**:\n",
        "- `iql_policy.d3` - Trained IQL model\n",
        "- `iql_actor_state.pt` - Actor weights for SAC warm-start\n",
        "- `equity_BTCUSDT_IQLonly.html` - Equity curve (offline only)\n",
        "- `candlestick_BTCUSDT_SepOct2025_IQLonly.html` - Trading signals\n",
        "- `summary_report_BTCUSDT_IQLonly.txt` - Performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "# Apply cloud parameter overrides by modifying config files in-memory\n",
        "# This keeps repo YAMLs unchanged while using cloud-optimized values\n",
        "\n",
        "# Override training steps (if QA_STEPS not set)\n",
        "if [ -z \"$QA_STEPS\" ]; then\n",
        "    echo \"Using cloud-optimized IQL steps: $CLOUD_IQL_STEPS\"\n",
        "    # Temporarily patch the config for this run\n",
        "    python -c \"\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "cfg_path = Path('config/algo_iql.yaml')\n",
        "cfg = yaml.safe_load(cfg_path.read_text())\n",
        "cfg['grad_steps_IQL'] = int('$CLOUD_IQL_STEPS')\n",
        "cfg['batch_size'] = int('$CLOUD_BATCH_SIZE')\n",
        "\n",
        "# Update network architecture if cloud override is set\n",
        "if '$CLOUD_HIDDEN_UNITS':\n",
        "    hidden = [int(x) for x in '$CLOUD_HIDDEN_UNITS'.split(',')]\n",
        "    cfg['actor_encoder_factory']['params']['hidden_units'] = hidden\n",
        "    cfg['critic_encoder_factory']['params']['hidden_units'] = hidden\n",
        "    cfg['value_encoder_factory']['params']['hidden_units'] = hidden\n",
        "\n",
        "cfg_path.write_text(yaml.dump(cfg, default_flow_style=False))\n",
        "print(f'✓ Updated algo_iql.yaml: {cfg[\\\"grad_steps_IQL\\\"]} steps, batch={cfg[\\\"batch_size\\\"]}')\n",
        "\"\n",
        "fi\n",
        "\n",
        "# Run IQL pretraining\n",
        "echo \"\"\n",
        "echo \"==========================================\"\n",
        "echo \"Starting IQL Offline Pretraining...\"\n",
        "echo \"==========================================\"\n",
        "python src/drl/offline/iql_pretrain.py\n",
        "\n",
        "echo \"\"\n",
        "echo \"==========================================\"\n",
        "echo \"IQL Training Complete!\"\n",
        "echo \"==========================================\"\n",
        "echo \"Saved artifacts:\"\n",
        "ls -lh evaluation/artifacts/iql_*.d3 evaluation/artifacts/iql_*.pt 2>/dev/null || echo \"  (check evaluation/artifacts/)\"\n",
        "echo \"\"\n",
        "echo \"IQL-only evaluation files:\"\n",
        "ls -lh evaluation/charts/*IQLonly.html evaluation/reports/*IQLonly.txt 2>/dev/null || echo \"  (check evaluation/ directories)\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dadbcb68",
      "metadata": {},
      "source": [
        "## 3) View IQL-Only Results (Offline Baseline)\n",
        "\n",
        "Before SAC fine-tuning, check the IQL-only performance to establish baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e03003",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import IFrame, display, Markdown\n",
        "\n",
        "# Display IQL-only summary report\n",
        "print(\"=\" * 80)\n",
        "print(\"IQL-ONLY PERFORMANCE (Offline Baseline)\")\n",
        "print(\"=\" * 80)\n",
        "report_path = 'evaluation/reports/summary_report_BTCUSDT_IQLonly.txt'\n",
        "if os.path.exists(report_path):\n",
        "    with open(report_path, 'r', encoding='utf-8') as f:\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(\"⚠️  IQL-only report not found. Training may have failed.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"IQL-ONLY CHARTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Display equity curve\n",
        "equity_path = 'evaluation/charts/equity_BTCUSDT_IQLonly.html'\n",
        "if os.path.exists(equity_path):\n",
        "    display(Markdown(\"### IQL-Only Equity Curve\"))\n",
        "    display(IFrame(equity_path, width=1000, height=500))\n",
        "else:\n",
        "    print(\"⚠️  IQL equity chart not found\")\n",
        "\n",
        "# Display candlestick chart\n",
        "candle_path = 'evaluation/charts/candlestick_BTCUSDT_SepOct2025_IQLonly.html'\n",
        "if os.path.exists(candle_path):\n",
        "    display(Markdown(\"### IQL-Only Trading Signals\"))\n",
        "    display(IFrame(candle_path, width=1000, height=500))\n",
        "else:\n",
        "    print(\"⚠️  IQL candlestick chart not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b771b14",
      "metadata": {},
      "source": [
        "## 4) SAC Online Fine-Tuning (100K steps, ~1-2 hours)\n",
        "\n",
        "Loads the IQL pretrained weights and fine-tunes with online environment interaction using SAC.\n",
        "\n",
        "**What happens**:\n",
        "- Loads IQL actor weights as warm-start\n",
        "- Runs online SAC training with replay buffer\n",
        "- Updates policy via TD3-style soft actor-critic\n",
        "- Saves final model to `evaluation/artifacts/sac_policy.d3`\n",
        "\n",
        "**Expected Improvement**:\n",
        "- IQL provides good initialization from offline data\n",
        "- SAC refines policy through online exploration\n",
        "- Should improve Sharpe ratio, reduce drawdown vs IQL-only baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d84d2a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "# Apply cloud parameter overrides for SAC\n",
        "if [ -z \"$QA_STEPS\" ]; then\n",
        "    echo \"Using cloud-optimized SAC steps: $CLOUD_SAC_STEPS\"\n",
        "    python -c \"\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "cfg_path = Path('config/algo_sac.yaml')\n",
        "cfg = yaml.safe_load(cfg_path.read_text())\n",
        "cfg['grad_steps_SAC'] = int('$CLOUD_SAC_STEPS')\n",
        "cfg['batch_size'] = int('$CLOUD_BATCH_SIZE')\n",
        "\n",
        "# Update network architecture if cloud override is set\n",
        "if '$CLOUD_HIDDEN_UNITS':\n",
        "    hidden = [int(x) for x in '$CLOUD_HIDDEN_UNITS'.split(',')]\n",
        "    cfg['actor_encoder_factory']['params']['hidden_units'] = hidden\n",
        "    cfg['critic_encoder_factory']['params']['hidden_units'] = hidden\n",
        "\n",
        "cfg_path.write_text(yaml.dump(cfg, default_flow_style=False))\n",
        "print(f'✓ Updated algo_sac.yaml: {cfg[\\\"grad_steps_SAC\\\"]} steps, batch={cfg[\\\"batch_size\\\"]}')\n",
        "\"\n",
        "fi\n",
        "\n",
        "# Run SAC fine-tuning\n",
        "echo \"\"\n",
        "echo \"==========================================\"\n",
        "echo \"Starting SAC Online Fine-Tuning...\"\n",
        "echo \"==========================================\"\n",
        "python src/drl/online/sac_train.py\n",
        "\n",
        "echo \"\"\n",
        "echo \"==========================================\"\n",
        "echo \"SAC Training Complete!\"\n",
        "echo \"==========================================\"\n",
        "echo \"Saved artifacts:\"\n",
        "ls -lh evaluation/artifacts/sac_*.d3 evaluation/artifacts/sac_*.pt 2>/dev/null || echo \"  (check evaluation/artifacts/)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Final Evaluation (SAC-Finetuned Model)\n",
        "\n",
        "Evaluates the SAC-finetuned model on the test period with warm-up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "echo \"==========================================\"\n",
        "echo \"Running Final Evaluation (SAC Model)...\"\n",
        "echo \"==========================================\"\n",
        "python -m src.run_walkforward --config config/config.yaml --device cuda\n",
        "\n",
        "echo \"\"\n",
        "echo \"==========================================\"\n",
        "echo \"Evaluation Complete!\"\n",
        "echo \"==========================================\"\n",
        "echo \"Final results:\"\n",
        "ls -lh evaluation/charts/equity_BTCUSDT.html evaluation/reports/summary_report_BTCUSDT.txt 2>/dev/null || echo \"  (check evaluation/ directories)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Compare Results: IQL-Only vs SAC-Finetuned\n",
        "\n",
        "View final charts and compare performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import IFrame, display, Markdown\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PERFORMANCE COMPARISON: IQL-Only vs SAC-Finetuned\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Read both reports\n",
        "iql_report_path = 'evaluation/reports/summary_report_BTCUSDT_IQLonly.txt'\n",
        "sac_report_path = 'evaluation/reports/summary_report_BTCUSDT.txt'\n",
        "\n",
        "if os.path.exists(iql_report_path):\n",
        "    print(\"\\n📊 IQL-ONLY (Offline Baseline)\")\n",
        "    print(\"-\" * 80)\n",
        "    with open(iql_report_path, 'r', encoding='utf-8') as f:\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(\"\\n⚠️  IQL-only report not found\")\n",
        "\n",
        "if os.path.exists(sac_report_path):\n",
        "    print(\"\\n📊 SAC-FINETUNED (Final Model)\")\n",
        "    print(\"-\" * 80)\n",
        "    with open(sac_report_path, 'r', encoding='utf-8') as f:\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(\"\\n⚠️  SAC report not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"VISUAL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Display SAC equity curve\n",
        "display(Markdown(\"### SAC-Finetuned Equity Curve\"))\n",
        "if os.path.exists('evaluation/charts/equity_BTCUSDT.html'):\n",
        "    display(IFrame('evaluation/charts/equity_BTCUSDT.html', width=1000, height=500))\n",
        "else:\n",
        "    print(\"⚠️  SAC equity chart not found\")\n",
        "\n",
        "# Display SAC candlestick\n",
        "display(Markdown(\"### SAC-Finetuned Trading Signals\"))\n",
        "if os.path.exists('evaluation/charts/candlestick_BTCUSDT_SepOct2025.html'):\n",
        "    display(IFrame('evaluation/charts/candlestick_BTCUSDT_SepOct2025.html', width=1000, height=500))\n",
        "else:\n",
        "    print(\"⚠️  SAC candlestick chart not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"✓ Training Complete! Compare metrics above to see SAC improvement over IQL.\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e152649",
      "metadata": {},
      "source": [
        "## 7) Download Results & Models\n",
        "\n",
        "Package all results for local analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb028f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "echo \"Packaging results...\"\n",
        "cd /content/algo-drl-sac-iql\n",
        "\n",
        "# Create results archive\n",
        "tar -czf results_cloud_training.tar.gz \\\n",
        "    evaluation/artifacts/*.d3 \\\n",
        "    evaluation/artifacts/*.pt \\\n",
        "    evaluation/charts/*.html \\\n",
        "    evaluation/reports/*.txt \\\n",
        "    evaluation/reports/*.csv \\\n",
        "    evaluation/reports/*.json \\\n",
        "    d3rlpy_logs/IQLWithAuxiliary_*/params.json \\\n",
        "    d3rlpy_logs/SAC_*/params.json \\\n",
        "    2>/dev/null || true\n",
        "\n",
        "echo \"\"\n",
        "echo \"==========================================\"\n",
        "echo \"Results packaged: results_cloud_training.tar.gz\"\n",
        "echo \"==========================================\"\n",
        "ls -lh results_cloud_training.tar.gz\n",
        "echo \"\"\n",
        "echo \"Download this file from Colab's file browser (left sidebar)\"\n",
        "echo \"or use Google Drive integration to save it.\"\n",
        "echo \"==========================================\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
